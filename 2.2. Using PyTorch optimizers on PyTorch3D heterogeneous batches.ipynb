{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fa7acd",
   "metadata": {},
   "source": [
    "3D data is usually heterogeneous: meshes within one mini-batch may contain different numbers of vertices and faces. Processing such data on GPUs efficiently is not trivial and coding for the heterogeneous mini-batch processing can also be tedious. \n",
    "\n",
    "Luckily, PyTorch3D has the capacity to handle heterogeneous mini-batches very efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b3a1c",
   "metadata": {},
   "source": [
    "Assuming the orientation of the camera is known, **let's estimate the unknown location of the depth camera** using the sensing results of the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe65eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f2cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.io import load_objs_as_meshes\n",
    "from pytorch3d.structures.meshes import join_meshes_as_batch\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import chamfer_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d33aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU only, this will be slow!\n"
     ]
    }
   ],
   "source": [
    "# Defining a torch device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: CPU only, this will be slow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47822c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "mesh_names = ['cube.obj', 'diamond.obj', 'dodecahedron.obj'] # the camera observes three objects in the scene \n",
    "                                                             # and we know the ground-truth mesh models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6aad1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Having a look at the obj meshes\n",
    "for mesh_name in mesh_names:\n",
    "    mesh = open3d.io.read_triangle_mesh(os.path.join(data_path, mesh_name))\n",
    "    open3d.visualization.draw_geometries([mesh], \n",
    "                                         mesh_show_wireframe = True, \n",
    "                                         mesh_show_back_face = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf2ed29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the same meshes with PyTorch3D, building mesh_list\n",
    "mesh_list = list()\n",
    "\n",
    "for mesh_name in mesh_names:\n",
    "    mesh = load_objs_as_meshes([os.path.join(data_path, mesh_name)], device=device)\n",
    "    mesh_list.append(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90326706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PyTorch3D mini-batch of meshes\n",
    "mesh_batch = join_meshes_as_batch(mesh_list, include_textures = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bee87d",
   "metadata": {},
   "source": [
    "There are three ways to represent vertices and faces in each PyTorch3D mini-batch:\n",
    "- List format\n",
    "- Padded format\n",
    "- Packed format\n",
    "\n",
    "The formats can be converted between each other efficiently by using the PyTorch3D API.\n",
    "Each of the three representations has its pros and cons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d90afcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex_list: \n",
      " [tensor([[-0.5000, -0.5000,  0.5000],\n",
      "        [-0.5000, -0.5000, -0.5000],\n",
      "        [-0.5000,  0.5000, -0.5000],\n",
      "        [-0.5000,  0.5000,  0.5000],\n",
      "        [ 0.5000, -0.5000,  0.5000],\n",
      "        [ 0.5000, -0.5000, -0.5000],\n",
      "        [ 0.5000,  0.5000, -0.5000],\n",
      "        [ 0.5000,  0.5000,  0.5000]]), tensor([[  0.,   0.,  78.],\n",
      "        [ 45.,  45.,   0.],\n",
      "        [ 45., -45.,   0.],\n",
      "        [-45., -45.,   0.],\n",
      "        [-45.,  45.,   0.],\n",
      "        [  0.,   0., -78.]]), tensor([[-0.5774, -0.5774,  0.5774],\n",
      "        [ 0.9342,  0.3568,  0.0000],\n",
      "        [ 0.9342, -0.3568,  0.0000],\n",
      "        [-0.9342,  0.3568,  0.0000],\n",
      "        [-0.9342, -0.3568,  0.0000],\n",
      "        [ 0.0000,  0.9342,  0.3568],\n",
      "        [ 0.0000,  0.9342, -0.3568],\n",
      "        [ 0.3568,  0.0000, -0.9342],\n",
      "        [-0.3568,  0.0000, -0.9342],\n",
      "        [ 0.0000, -0.9342, -0.3568],\n",
      "        [ 0.0000, -0.9342,  0.3568],\n",
      "        [ 0.3568,  0.0000,  0.9342],\n",
      "        [-0.3568,  0.0000,  0.9342],\n",
      "        [ 0.5774,  0.5774, -0.5774],\n",
      "        [ 0.5774,  0.5774,  0.5774],\n",
      "        [-0.5774,  0.5774, -0.5774],\n",
      "        [-0.5774,  0.5774,  0.5774],\n",
      "        [ 0.5774, -0.5774, -0.5774],\n",
      "        [ 0.5774, -0.5774,  0.5774],\n",
      "        [-0.5774, -0.5774, -0.5774]])]\n",
      "face_list: \n",
      " [tensor([[0, 1, 2],\n",
      "        [5, 4, 7],\n",
      "        [6, 2, 1],\n",
      "        [3, 7, 4],\n",
      "        [7, 3, 2],\n",
      "        [5, 1, 0],\n",
      "        [0, 2, 3],\n",
      "        [5, 7, 6],\n",
      "        [6, 1, 5],\n",
      "        [3, 4, 0],\n",
      "        [7, 2, 6],\n",
      "        [5, 0, 4]]), tensor([[0, 1, 2],\n",
      "        [0, 2, 3],\n",
      "        [0, 3, 4],\n",
      "        [0, 4, 1],\n",
      "        [5, 4, 3],\n",
      "        [5, 3, 2],\n",
      "        [5, 2, 1],\n",
      "        [5, 1, 0],\n",
      "        [5, 0, 4]]), tensor([[18,  2,  1],\n",
      "        [11, 18,  1],\n",
      "        [14, 11,  1],\n",
      "        [ 7, 13,  1],\n",
      "        [17,  7,  1],\n",
      "        [ 2, 17,  1],\n",
      "        [19,  4,  3],\n",
      "        [ 8, 19,  3],\n",
      "        [15,  8,  3],\n",
      "        [12, 16,  3],\n",
      "        [ 0, 12,  3],\n",
      "        [ 4,  0,  3],\n",
      "        [ 6, 15,  3],\n",
      "        [ 5,  6,  3],\n",
      "        [16,  5,  3],\n",
      "        [ 5, 14,  1],\n",
      "        [ 6,  5,  1],\n",
      "        [13,  6,  1],\n",
      "        [ 9, 17,  2],\n",
      "        [10,  9,  2],\n",
      "        [18, 10,  2],\n",
      "        [10,  0,  4],\n",
      "        [ 9, 10,  4],\n",
      "        [19,  9,  4],\n",
      "        [19,  8,  7],\n",
      "        [ 9, 19,  7],\n",
      "        [17,  9,  7],\n",
      "        [ 8, 15,  6],\n",
      "        [ 7,  8,  6],\n",
      "        [13,  7,  6],\n",
      "        [11, 14,  5],\n",
      "        [12, 11,  5],\n",
      "        [16, 12,  5],\n",
      "        [12,  0, 10],\n",
      "        [11, 12, 10],\n",
      "        [18, 11, 10]])]\n"
     ]
    }
   ],
   "source": [
    "# Returning vertices and faces in a list format\n",
    "vertex_list = mesh_batch.verts_list()\n",
    "face_list = mesh_batch.faces_list()\n",
    "\n",
    "print('vertex_list: \\n', vertex_list)\n",
    "print('face_list: \\n', face_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d067de2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex_padded: \n",
      " tensor([[[ -0.5000,  -0.5000,   0.5000],\n",
      "         [ -0.5000,  -0.5000,  -0.5000],\n",
      "         [ -0.5000,   0.5000,  -0.5000],\n",
      "         [ -0.5000,   0.5000,   0.5000],\n",
      "         [  0.5000,  -0.5000,   0.5000],\n",
      "         [  0.5000,  -0.5000,  -0.5000],\n",
      "         [  0.5000,   0.5000,  -0.5000],\n",
      "         [  0.5000,   0.5000,   0.5000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,  78.0000],\n",
      "         [ 45.0000,  45.0000,   0.0000],\n",
      "         [ 45.0000, -45.0000,   0.0000],\n",
      "         [-45.0000, -45.0000,   0.0000],\n",
      "         [-45.0000,  45.0000,   0.0000],\n",
      "         [  0.0000,   0.0000, -78.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[ -0.5774,  -0.5774,   0.5774],\n",
      "         [  0.9342,   0.3568,   0.0000],\n",
      "         [  0.9342,  -0.3568,   0.0000],\n",
      "         [ -0.9342,   0.3568,   0.0000],\n",
      "         [ -0.9342,  -0.3568,   0.0000],\n",
      "         [  0.0000,   0.9342,   0.3568],\n",
      "         [  0.0000,   0.9342,  -0.3568],\n",
      "         [  0.3568,   0.0000,  -0.9342],\n",
      "         [ -0.3568,   0.0000,  -0.9342],\n",
      "         [  0.0000,  -0.9342,  -0.3568],\n",
      "         [  0.0000,  -0.9342,   0.3568],\n",
      "         [  0.3568,   0.0000,   0.9342],\n",
      "         [ -0.3568,   0.0000,   0.9342],\n",
      "         [  0.5774,   0.5774,  -0.5774],\n",
      "         [  0.5774,   0.5774,   0.5774],\n",
      "         [ -0.5774,   0.5774,  -0.5774],\n",
      "         [ -0.5774,   0.5774,   0.5774],\n",
      "         [  0.5774,  -0.5774,  -0.5774],\n",
      "         [  0.5774,  -0.5774,   0.5774],\n",
      "         [ -0.5774,  -0.5774,  -0.5774]]])\n",
      "face_padded: \n",
      " tensor([[[ 0,  1,  2],\n",
      "         [ 5,  4,  7],\n",
      "         [ 6,  2,  1],\n",
      "         [ 3,  7,  4],\n",
      "         [ 7,  3,  2],\n",
      "         [ 5,  1,  0],\n",
      "         [ 0,  2,  3],\n",
      "         [ 5,  7,  6],\n",
      "         [ 6,  1,  5],\n",
      "         [ 3,  4,  0],\n",
      "         [ 7,  2,  6],\n",
      "         [ 5,  0,  4],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1]],\n",
      "\n",
      "        [[ 0,  1,  2],\n",
      "         [ 0,  2,  3],\n",
      "         [ 0,  3,  4],\n",
      "         [ 0,  4,  1],\n",
      "         [ 5,  4,  3],\n",
      "         [ 5,  3,  2],\n",
      "         [ 5,  2,  1],\n",
      "         [ 5,  1,  0],\n",
      "         [ 5,  0,  4],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1],\n",
      "         [-1, -1, -1]],\n",
      "\n",
      "        [[18,  2,  1],\n",
      "         [11, 18,  1],\n",
      "         [14, 11,  1],\n",
      "         [ 7, 13,  1],\n",
      "         [17,  7,  1],\n",
      "         [ 2, 17,  1],\n",
      "         [19,  4,  3],\n",
      "         [ 8, 19,  3],\n",
      "         [15,  8,  3],\n",
      "         [12, 16,  3],\n",
      "         [ 0, 12,  3],\n",
      "         [ 4,  0,  3],\n",
      "         [ 6, 15,  3],\n",
      "         [ 5,  6,  3],\n",
      "         [16,  5,  3],\n",
      "         [ 5, 14,  1],\n",
      "         [ 6,  5,  1],\n",
      "         [13,  6,  1],\n",
      "         [ 9, 17,  2],\n",
      "         [10,  9,  2],\n",
      "         [18, 10,  2],\n",
      "         [10,  0,  4],\n",
      "         [ 9, 10,  4],\n",
      "         [19,  9,  4],\n",
      "         [19,  8,  7],\n",
      "         [ 9, 19,  7],\n",
      "         [17,  9,  7],\n",
      "         [ 8, 15,  6],\n",
      "         [ 7,  8,  6],\n",
      "         [13,  7,  6],\n",
      "         [11, 14,  5],\n",
      "         [12, 11,  5],\n",
      "         [16, 12,  5],\n",
      "         [12,  0, 10],\n",
      "         [11, 12, 10],\n",
      "         [18, 11, 10]]])\n"
     ]
    }
   ],
   "source": [
    "# Returning vertices and faces in the padded format\n",
    "vertex_padded = mesh_batch.verts_padded()\n",
    "face_padded = mesh_batch.faces_padded()\n",
    "\n",
    "print('vertex_padded: \\n', vertex_padded)\n",
    "print('face_padded: \\n', face_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c4a6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex_packed: \n",
      " tensor([[ -0.5000,  -0.5000,   0.5000],\n",
      "        [ -0.5000,  -0.5000,  -0.5000],\n",
      "        [ -0.5000,   0.5000,  -0.5000],\n",
      "        [ -0.5000,   0.5000,   0.5000],\n",
      "        [  0.5000,  -0.5000,   0.5000],\n",
      "        [  0.5000,  -0.5000,  -0.5000],\n",
      "        [  0.5000,   0.5000,  -0.5000],\n",
      "        [  0.5000,   0.5000,   0.5000],\n",
      "        [  0.0000,   0.0000,  78.0000],\n",
      "        [ 45.0000,  45.0000,   0.0000],\n",
      "        [ 45.0000, -45.0000,   0.0000],\n",
      "        [-45.0000, -45.0000,   0.0000],\n",
      "        [-45.0000,  45.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, -78.0000],\n",
      "        [ -0.5774,  -0.5774,   0.5774],\n",
      "        [  0.9342,   0.3568,   0.0000],\n",
      "        [  0.9342,  -0.3568,   0.0000],\n",
      "        [ -0.9342,   0.3568,   0.0000],\n",
      "        [ -0.9342,  -0.3568,   0.0000],\n",
      "        [  0.0000,   0.9342,   0.3568],\n",
      "        [  0.0000,   0.9342,  -0.3568],\n",
      "        [  0.3568,   0.0000,  -0.9342],\n",
      "        [ -0.3568,   0.0000,  -0.9342],\n",
      "        [  0.0000,  -0.9342,  -0.3568],\n",
      "        [  0.0000,  -0.9342,   0.3568],\n",
      "        [  0.3568,   0.0000,   0.9342],\n",
      "        [ -0.3568,   0.0000,   0.9342],\n",
      "        [  0.5774,   0.5774,  -0.5774],\n",
      "        [  0.5774,   0.5774,   0.5774],\n",
      "        [ -0.5774,   0.5774,  -0.5774],\n",
      "        [ -0.5774,   0.5774,   0.5774],\n",
      "        [  0.5774,  -0.5774,  -0.5774],\n",
      "        [  0.5774,  -0.5774,   0.5774],\n",
      "        [ -0.5774,  -0.5774,  -0.5774]])\n",
      "face_packed: \n",
      " tensor([[ 0,  1,  2],\n",
      "        [ 5,  4,  7],\n",
      "        [ 6,  2,  1],\n",
      "        [ 3,  7,  4],\n",
      "        [ 7,  3,  2],\n",
      "        [ 5,  1,  0],\n",
      "        [ 0,  2,  3],\n",
      "        [ 5,  7,  6],\n",
      "        [ 6,  1,  5],\n",
      "        [ 3,  4,  0],\n",
      "        [ 7,  2,  6],\n",
      "        [ 5,  0,  4],\n",
      "        [ 8,  9, 10],\n",
      "        [ 8, 10, 11],\n",
      "        [ 8, 11, 12],\n",
      "        [ 8, 12,  9],\n",
      "        [13, 12, 11],\n",
      "        [13, 11, 10],\n",
      "        [13, 10,  9],\n",
      "        [13,  9,  8],\n",
      "        [13,  8, 12],\n",
      "        [32, 16, 15],\n",
      "        [25, 32, 15],\n",
      "        [28, 25, 15],\n",
      "        [21, 27, 15],\n",
      "        [31, 21, 15],\n",
      "        [16, 31, 15],\n",
      "        [33, 18, 17],\n",
      "        [22, 33, 17],\n",
      "        [29, 22, 17],\n",
      "        [26, 30, 17],\n",
      "        [14, 26, 17],\n",
      "        [18, 14, 17],\n",
      "        [20, 29, 17],\n",
      "        [19, 20, 17],\n",
      "        [30, 19, 17],\n",
      "        [19, 28, 15],\n",
      "        [20, 19, 15],\n",
      "        [27, 20, 15],\n",
      "        [23, 31, 16],\n",
      "        [24, 23, 16],\n",
      "        [32, 24, 16],\n",
      "        [24, 14, 18],\n",
      "        [23, 24, 18],\n",
      "        [33, 23, 18],\n",
      "        [33, 22, 21],\n",
      "        [23, 33, 21],\n",
      "        [31, 23, 21],\n",
      "        [22, 29, 20],\n",
      "        [21, 22, 20],\n",
      "        [27, 21, 20],\n",
      "        [25, 28, 19],\n",
      "        [26, 25, 19],\n",
      "        [30, 26, 19],\n",
      "        [26, 14, 24],\n",
      "        [25, 26, 24],\n",
      "        [32, 25, 24]])\n",
      "num_vertices =  34\n"
     ]
    }
   ],
   "source": [
    "# Getting vertices and faces in the packed format\n",
    "vertex_packed = mesh_batch.verts_packed()\n",
    "face_packed = mesh_batch.faces_packed()\n",
    "print('vertex_packed: \\n', vertex_packed)\n",
    "print('face_packed: \\n', face_packed)\n",
    "\n",
    "num_vertices = vertex_packed.shape[0]\n",
    "print('num_vertices = ', num_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79c3778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motion ground truth =  tensor([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Simulating a noisy and displaced version of the three meshes\n",
    "mesh_batch_noisy = mesh_batch.clone() # clone the ground truth mesh models\n",
    "noise = (0.1**0.5)*torch.randn(mesh_batch_noisy.verts_packed().shape).to(device) #generate random Gaussian noise\n",
    "motion_gt = np.array([3, 4, 5])\n",
    "motion_gt = torch.as_tensor(motion_gt)\n",
    "print('motion ground truth = ', motion_gt)\n",
    "\n",
    "motion_gt = motion_gt[None, :]\n",
    "motion_gt = motion_gt.to(device)\n",
    "noise = noise + motion_gt\n",
    "\n",
    "mesh_batch_noisy = mesh_batch_noisy.offset_verts(noise).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a924048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0 , motion_estimation =  tensor([[0.7660, 1.0591, 1.3091]], requires_grad=True)\n",
      "i =  1 , motion_estimation =  tensor([[1.9890, 2.7370, 3.4198]], requires_grad=True)\n",
      "i =  2 , motion_estimation =  tensor([[3.2689, 4.4703, 5.6283]], requires_grad=True)\n",
      "i =  3 , motion_estimation =  tensor([[4.3714, 5.9458, 7.5484]], requires_grad=True)\n",
      "i =  4 , motion_estimation =  tensor([[5.0222, 6.7549, 8.7200]], requires_grad=True)\n",
      "i =  5 , motion_estimation =  tensor([[5.0668, 6.7020, 8.8755]], requires_grad=True)\n",
      "i =  6 , motion_estimation =  tensor([[4.5661, 5.8858, 8.0746]], requires_grad=True)\n",
      "i =  7 , motion_estimation =  tensor([[3.7233, 4.6184, 6.6561]], requires_grad=True)\n",
      "i =  8 , motion_estimation =  tensor([[2.8137, 3.3175, 5.1016]], requires_grad=True)\n",
      "i =  9 , motion_estimation =  tensor([[2.0189, 2.2299, 3.7003]], requires_grad=True)\n",
      "i =  10 , motion_estimation =  tensor([[1.4702, 1.6002, 2.6817]], requires_grad=True)\n",
      "i =  11 , motion_estimation =  tensor([[1.2992, 1.5865, 2.2981]], requires_grad=True)\n",
      "i =  12 , motion_estimation =  tensor([[1.5187, 2.1338, 2.5942]], requires_grad=True)\n",
      "i =  13 , motion_estimation =  tensor([[2.0268, 3.0234, 3.4138]], requires_grad=True)\n",
      "i =  14 , motion_estimation =  tensor([[2.6534, 3.9756, 4.4534]], requires_grad=True)\n",
      "i =  15 , motion_estimation =  tensor([[3.2648, 4.8305, 5.4569]], requires_grad=True)\n",
      "i =  16 , motion_estimation =  tensor([[3.7621, 5.4502, 6.3094]], requires_grad=True)\n",
      "i =  17 , motion_estimation =  tensor([[4.0281, 5.6703, 6.8517]], requires_grad=True)\n",
      "i =  18 , motion_estimation =  tensor([[4.0136, 5.4485, 6.9722]], requires_grad=True)\n",
      "i =  19 , motion_estimation =  tensor([[3.7613, 4.8843, 6.6888]], requires_grad=True)\n",
      "i =  20 , motion_estimation =  tensor([[3.3683, 4.1590, 6.1396]], requires_grad=True)\n",
      "i =  21 , motion_estimation =  tensor([[2.9549, 3.4590, 5.5092]], requires_grad=True)\n",
      "i =  22 , motion_estimation =  tensor([[2.5904, 2.8907, 4.9015]], requires_grad=True)\n",
      "i =  23 , motion_estimation =  tensor([[2.3167, 2.5424, 4.3683]], requires_grad=True)\n",
      "i =  24 , motion_estimation =  tensor([[2.1693, 2.4873, 3.9745]], requires_grad=True)\n",
      "i =  25 , motion_estimation =  tensor([[2.1625, 2.7125, 3.7826]], requires_grad=True)\n",
      "i =  26 , motion_estimation =  tensor([[2.2847, 3.1309, 3.8207]], requires_grad=True)\n",
      "i =  27 , motion_estimation =  tensor([[2.5009, 3.6338, 4.0505]], requires_grad=True)\n",
      "i =  28 , motion_estimation =  tensor([[2.7620, 4.1265, 4.3877]], requires_grad=True)\n",
      "i =  29 , motion_estimation =  tensor([[3.0296, 4.5514, 4.7654]], requires_grad=True)\n",
      "i =  30 , motion_estimation =  tensor([[3.2630, 4.8515, 5.1322]], requires_grad=True)\n",
      "i =  31 , motion_estimation =  tensor([[3.4253, 4.9806, 5.4461]], requires_grad=True)\n",
      "i =  32 , motion_estimation =  tensor([[3.4905, 4.9171, 5.6690]], requires_grad=True)\n",
      "i =  33 , motion_estimation =  tensor([[3.4520, 4.6794, 5.7834]], requires_grad=True)\n",
      "i =  34 , motion_estimation =  tensor([[3.3313, 4.3326, 5.7916]], requires_grad=True)\n",
      "i =  35 , motion_estimation =  tensor([[3.1646, 3.9513, 5.7189]], requires_grad=True)\n",
      "i =  36 , motion_estimation =  tensor([[2.9907, 3.6014, 5.5850]], requires_grad=True)\n",
      "i =  37 , motion_estimation =  tensor([[2.8380, 3.3299, 5.4115]], requires_grad=True)\n",
      "i =  38 , motion_estimation =  tensor([[2.7213, 3.1682, 5.2204]], requires_grad=True)\n",
      "i =  39 , motion_estimation =  tensor([[2.6535, 3.1316, 5.0328]], requires_grad=True)\n",
      "i =  40 , motion_estimation =  tensor([[2.6369, 3.2124, 4.8650]], requires_grad=True)\n",
      "i =  41 , motion_estimation =  tensor([[2.6665, 3.3820, 4.7340]], requires_grad=True)\n",
      "i =  42 , motion_estimation =  tensor([[2.7319, 3.6086, 4.6522]], requires_grad=True)\n",
      "i =  43 , motion_estimation =  tensor([[2.8223, 3.8553, 4.6221]], requires_grad=True)\n",
      "i =  44 , motion_estimation =  tensor([[2.9247, 4.0888, 4.6401]], requires_grad=True)\n",
      "i =  45 , motion_estimation =  tensor([[3.0247, 4.2824, 4.7005]], requires_grad=True)\n",
      "i =  46 , motion_estimation =  tensor([[3.1077, 4.4159, 4.7924]], requires_grad=True)\n",
      "i =  47 , motion_estimation =  tensor([[3.1656, 4.4765, 4.9003]], requires_grad=True)\n",
      "i =  48 , motion_estimation =  tensor([[3.1923, 4.4581, 5.0096]], requires_grad=True)\n",
      "i =  49 , motion_estimation =  tensor([[3.1849, 4.3718, 5.1131]], requires_grad=True)\n",
      "i =  50 , motion_estimation =  tensor([[3.1481, 4.2338, 5.2005]], requires_grad=True)\n",
      "i =  51 , motion_estimation =  tensor([[3.0924, 4.0703, 5.2676]], requires_grad=True)\n",
      "i =  52 , motion_estimation =  tensor([[3.0277, 3.9053, 5.3097]], requires_grad=True)\n",
      "i =  53 , motion_estimation =  tensor([[2.9642, 3.7608, 5.3275]], requires_grad=True)\n",
      "i =  54 , motion_estimation =  tensor([[2.9112, 3.6534, 5.3228]], requires_grad=True)\n",
      "i =  55 , motion_estimation =  tensor([[2.8763, 3.5932, 5.2961]], requires_grad=True)\n",
      "i =  56 , motion_estimation =  tensor([[2.8596, 3.5849, 5.2512]], requires_grad=True)\n",
      "i =  57 , motion_estimation =  tensor([[2.8638, 3.6255, 5.1947]], requires_grad=True)\n",
      "i =  58 , motion_estimation =  tensor([[2.8864, 3.7036, 5.1299]], requires_grad=True)\n",
      "i =  59 , motion_estimation =  tensor([[2.9210, 3.8055, 5.0669]], requires_grad=True)\n",
      "i =  60 , motion_estimation =  tensor([[2.9606, 3.9150, 5.0131]], requires_grad=True)\n",
      "i =  61 , motion_estimation =  tensor([[2.9982, 4.0187, 4.9710]], requires_grad=True)\n",
      "i =  62 , motion_estimation =  tensor([[3.0289, 4.1035, 4.9453]], requires_grad=True)\n",
      "i =  63 , motion_estimation =  tensor([[3.0488, 4.1584, 4.9365]], requires_grad=True)\n",
      "i =  64 , motion_estimation =  tensor([[3.0575, 4.1819, 4.9382]], requires_grad=True)\n",
      "i =  65 , motion_estimation =  tensor([[3.0557, 4.1728, 4.9511]], requires_grad=True)\n",
      "i =  66 , motion_estimation =  tensor([[3.0442, 4.1345, 4.9740]], requires_grad=True)\n",
      "i =  67 , motion_estimation =  tensor([[3.0251, 4.0748, 5.0062]], requires_grad=True)\n",
      "i =  68 , motion_estimation =  tensor([[3.0033, 4.0039, 5.0439]], requires_grad=True)\n",
      "i =  69 , motion_estimation =  tensor([[2.9809, 3.9331, 5.0824]], requires_grad=True)\n",
      "i =  70 , motion_estimation =  tensor([[2.9608, 3.8680, 5.1174]], requires_grad=True)\n",
      "i =  71 , motion_estimation =  tensor([[2.9437, 3.8217, 5.1458]], requires_grad=True)\n",
      "i =  72 , motion_estimation =  tensor([[2.9335, 3.7971, 5.1643]], requires_grad=True)\n",
      "i =  73 , motion_estimation =  tensor([[2.9321, 3.7925, 5.1734]], requires_grad=True)\n",
      "i =  74 , motion_estimation =  tensor([[2.9385, 3.8087, 5.1714]], requires_grad=True)\n",
      "i =  75 , motion_estimation =  tensor([[2.9528, 3.8420, 5.1608]], requires_grad=True)\n",
      "i =  76 , motion_estimation =  tensor([[2.9683, 3.8815, 5.1437]], requires_grad=True)\n",
      "i =  77 , motion_estimation =  tensor([[2.9835, 3.9241, 5.1232]], requires_grad=True)\n",
      "i =  78 , motion_estimation =  tensor([[2.9982, 3.9640, 5.0988]], requires_grad=True)\n",
      "i =  79 , motion_estimation =  tensor([[3.0102, 3.9977, 5.0740]], requires_grad=True)\n",
      "i =  80 , motion_estimation =  tensor([[3.0187, 4.0216, 5.0550]], requires_grad=True)\n",
      "i =  81 , motion_estimation =  tensor([[3.0222, 4.0311, 5.0399]], requires_grad=True)\n",
      "i =  82 , motion_estimation =  tensor([[3.0203, 4.0284, 5.0302]], requires_grad=True)\n",
      "i =  83 , motion_estimation =  tensor([[3.0140, 4.0151, 5.0280]], requires_grad=True)\n",
      "i =  84 , motion_estimation =  tensor([[3.0047, 3.9937, 5.0297]], requires_grad=True)\n",
      "i =  85 , motion_estimation =  tensor([[2.9946, 3.9679, 5.0371]], requires_grad=True)\n",
      "i =  86 , motion_estimation =  tensor([[2.9830, 3.9407, 5.0503]], requires_grad=True)\n",
      "i =  87 , motion_estimation =  tensor([[2.9729, 3.9156, 5.0694]], requires_grad=True)\n",
      "i =  88 , motion_estimation =  tensor([[2.9655, 3.8979, 5.0867]], requires_grad=True)\n",
      "i =  89 , motion_estimation =  tensor([[2.9622, 3.8891, 5.1062]], requires_grad=True)\n",
      "i =  90 , motion_estimation =  tensor([[2.9630, 3.8880, 5.1216]], requires_grad=True)\n",
      "i =  91 , motion_estimation =  tensor([[2.9679, 3.8912, 5.1294]], requires_grad=True)\n",
      "i =  92 , motion_estimation =  tensor([[2.9743, 3.9039, 5.1294]], requires_grad=True)\n",
      "i =  93 , motion_estimation =  tensor([[2.9816, 3.9224, 5.1239]], requires_grad=True)\n",
      "i =  94 , motion_estimation =  tensor([[2.9889, 3.9424, 5.1155]], requires_grad=True)\n",
      "i =  95 , motion_estimation =  tensor([[2.9977, 3.9592, 5.1064]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  96 , motion_estimation =  tensor([[3.0023, 3.9722, 5.0977]], requires_grad=True)\n",
      "i =  97 , motion_estimation =  tensor([[3.0045, 3.9813, 5.0887]], requires_grad=True)\n",
      "i =  98 , motion_estimation =  tensor([[3.0012, 3.9843, 5.0799]], requires_grad=True)\n",
      "i =  99 , motion_estimation =  tensor([[2.9956, 3.9824, 5.0734]], requires_grad=True)\n",
      "i =  100 , motion_estimation =  tensor([[2.9900, 3.9747, 5.0663]], requires_grad=True)\n",
      "i =  101 , motion_estimation =  tensor([[2.9822, 3.9634, 5.0600]], requires_grad=True)\n",
      "i =  102 , motion_estimation =  tensor([[2.9740, 3.9506, 5.0566]], requires_grad=True)\n",
      "i =  103 , motion_estimation =  tensor([[2.9671, 3.9365, 5.0589]], requires_grad=True)\n",
      "i =  104 , motion_estimation =  tensor([[2.9606, 3.9244, 5.0633]], requires_grad=True)\n",
      "i =  105 , motion_estimation =  tensor([[2.9556, 3.9160, 5.0698]], requires_grad=True)\n",
      "i =  106 , motion_estimation =  tensor([[2.9539, 3.9104, 5.0779]], requires_grad=True)\n",
      "i =  107 , motion_estimation =  tensor([[2.9575, 3.9075, 5.0822]], requires_grad=True)\n",
      "i =  108 , motion_estimation =  tensor([[2.9653, 3.9098, 5.0871]], requires_grad=True)\n",
      "i =  109 , motion_estimation =  tensor([[2.9754, 3.9167, 5.0914]], requires_grad=True)\n",
      "i =  110 , motion_estimation =  tensor([[2.9846, 3.9262, 5.0962]], requires_grad=True)\n",
      "i =  111 , motion_estimation =  tensor([[2.9945, 3.9346, 5.0986]], requires_grad=True)\n",
      "i =  112 , motion_estimation =  tensor([[3.0015, 3.9436, 5.0979]], requires_grad=True)\n",
      "i =  113 , motion_estimation =  tensor([[3.0049, 3.9518, 5.0992]], requires_grad=True)\n",
      "i =  114 , motion_estimation =  tensor([[3.0030, 3.9577, 5.0999]], requires_grad=True)\n",
      "i =  115 , motion_estimation =  tensor([[2.9991, 3.9583, 5.1016]], requires_grad=True)\n",
      "i =  116 , motion_estimation =  tensor([[2.9934, 3.9546, 5.0989]], requires_grad=True)\n",
      "i =  117 , motion_estimation =  tensor([[2.9888, 3.9506, 5.0927]], requires_grad=True)\n",
      "i =  118 , motion_estimation =  tensor([[2.9820, 3.9468, 5.0871]], requires_grad=True)\n",
      "i =  119 , motion_estimation =  tensor([[2.9767, 3.9447, 5.0826]], requires_grad=True)\n",
      "i =  120 , motion_estimation =  tensor([[2.9722, 3.9437, 5.0799]], requires_grad=True)\n",
      "i =  121 , motion_estimation =  tensor([[2.9705, 3.9408, 5.0809]], requires_grad=True)\n",
      "i =  122 , motion_estimation =  tensor([[2.9691, 3.9397, 5.0810]], requires_grad=True)\n",
      "i =  123 , motion_estimation =  tensor([[2.9707, 3.9402, 5.0819]], requires_grad=True)\n",
      "i =  124 , motion_estimation =  tensor([[2.9727, 3.9403, 5.0822]], requires_grad=True)\n",
      "i =  125 , motion_estimation =  tensor([[2.9761, 3.9398, 5.0806]], requires_grad=True)\n",
      "i =  126 , motion_estimation =  tensor([[2.9776, 3.9391, 5.0798]], requires_grad=True)\n",
      "i =  127 , motion_estimation =  tensor([[2.9788, 3.9404, 5.0804]], requires_grad=True)\n",
      "i =  128 , motion_estimation =  tensor([[2.9805, 3.9417, 5.0831]], requires_grad=True)\n",
      "i =  129 , motion_estimation =  tensor([[2.9816, 3.9412, 5.0836]], requires_grad=True)\n",
      "i =  130 , motion_estimation =  tensor([[2.9825, 3.9405, 5.0853]], requires_grad=True)\n",
      "i =  131 , motion_estimation =  tensor([[2.9830, 3.9394, 5.0855]], requires_grad=True)\n",
      "i =  132 , motion_estimation =  tensor([[2.9830, 3.9375, 5.0859]], requires_grad=True)\n",
      "i =  133 , motion_estimation =  tensor([[2.9838, 3.9350, 5.0888]], requires_grad=True)\n",
      "i =  134 , motion_estimation =  tensor([[2.9845, 3.9339, 5.0931]], requires_grad=True)\n",
      "i =  135 , motion_estimation =  tensor([[2.9854, 3.9348, 5.0966]], requires_grad=True)\n",
      "i =  136 , motion_estimation =  tensor([[2.9865, 3.9367, 5.0989]], requires_grad=True)\n",
      "i =  137 , motion_estimation =  tensor([[2.9847, 3.9396, 5.0980]], requires_grad=True)\n",
      "i =  138 , motion_estimation =  tensor([[2.9807, 3.9456, 5.0952]], requires_grad=True)\n",
      "i =  139 , motion_estimation =  tensor([[2.9781, 3.9514, 5.0908]], requires_grad=True)\n",
      "i =  140 , motion_estimation =  tensor([[2.9763, 3.9555, 5.0842]], requires_grad=True)\n",
      "i =  141 , motion_estimation =  tensor([[2.9748, 3.9583, 5.0767]], requires_grad=True)\n",
      "i =  142 , motion_estimation =  tensor([[2.9758, 3.9580, 5.0695]], requires_grad=True)\n",
      "i =  143 , motion_estimation =  tensor([[2.9778, 3.9552, 5.0661]], requires_grad=True)\n",
      "i =  144 , motion_estimation =  tensor([[2.9781, 3.9498, 5.0635]], requires_grad=True)\n",
      "i =  145 , motion_estimation =  tensor([[2.9777, 3.9424, 5.0629]], requires_grad=True)\n",
      "i =  146 , motion_estimation =  tensor([[2.9795, 3.9366, 5.0669]], requires_grad=True)\n",
      "i =  147 , motion_estimation =  tensor([[2.9796, 3.9322, 5.0717]], requires_grad=True)\n",
      "i =  148 , motion_estimation =  tensor([[2.9802, 3.9282, 5.0774]], requires_grad=True)\n",
      "i =  149 , motion_estimation =  tensor([[2.9801, 3.9281, 5.0829]], requires_grad=True)\n",
      "i =  150 , motion_estimation =  tensor([[2.9801, 3.9276, 5.0905]], requires_grad=True)\n",
      "i =  151 , motion_estimation =  tensor([[2.9811, 3.9295, 5.1007]], requires_grad=True)\n",
      "i =  152 , motion_estimation =  tensor([[2.9826, 3.9318, 5.1092]], requires_grad=True)\n",
      "i =  153 , motion_estimation =  tensor([[2.9845, 3.9353, 5.1150]], requires_grad=True)\n",
      "i =  154 , motion_estimation =  tensor([[2.9846, 3.9396, 5.1184]], requires_grad=True)\n",
      "i =  155 , motion_estimation =  tensor([[2.9819, 3.9437, 5.1196]], requires_grad=True)\n",
      "i =  156 , motion_estimation =  tensor([[2.9793, 3.9494, 5.1157]], requires_grad=True)\n",
      "i =  157 , motion_estimation =  tensor([[2.9771, 3.9538, 5.1107]], requires_grad=True)\n",
      "i =  158 , motion_estimation =  tensor([[2.9755, 3.9562, 5.1061]], requires_grad=True)\n",
      "i =  159 , motion_estimation =  tensor([[2.9747, 3.9557, 5.1030]], requires_grad=True)\n",
      "i =  160 , motion_estimation =  tensor([[2.9736, 3.9549, 5.0998]], requires_grad=True)\n",
      "i =  161 , motion_estimation =  tensor([[2.9751, 3.9516, 5.0966]], requires_grad=True)\n",
      "i =  162 , motion_estimation =  tensor([[2.9789, 3.9467, 5.0943]], requires_grad=True)\n",
      "i =  163 , motion_estimation =  tensor([[2.9843, 3.9416, 5.0887]], requires_grad=True)\n",
      "i =  164 , motion_estimation =  tensor([[2.9909, 3.9361, 5.0846]], requires_grad=True)\n",
      "i =  165 , motion_estimation =  tensor([[2.9945, 3.9319, 5.0807]], requires_grad=True)\n",
      "i =  166 , motion_estimation =  tensor([[2.9959, 3.9293, 5.0776]], requires_grad=True)\n",
      "i =  167 , motion_estimation =  tensor([[2.9950, 3.9248, 5.0742]], requires_grad=True)\n",
      "i =  168 , motion_estimation =  tensor([[2.9940, 3.9236, 5.0731]], requires_grad=True)\n",
      "i =  169 , motion_estimation =  tensor([[2.9932, 3.9240, 5.0742]], requires_grad=True)\n",
      "i =  170 , motion_estimation =  tensor([[2.9916, 3.9268, 5.0754]], requires_grad=True)\n",
      "i =  171 , motion_estimation =  tensor([[2.9893, 3.9334, 5.0777]], requires_grad=True)\n",
      "i =  172 , motion_estimation =  tensor([[2.9849, 3.9407, 5.0796]], requires_grad=True)\n",
      "i =  173 , motion_estimation =  tensor([[2.9811, 3.9479, 5.0822]], requires_grad=True)\n",
      "i =  174 , motion_estimation =  tensor([[2.9776, 3.9558, 5.0867]], requires_grad=True)\n",
      "i =  175 , motion_estimation =  tensor([[2.9765, 3.9604, 5.0908]], requires_grad=True)\n",
      "i =  176 , motion_estimation =  tensor([[2.9763, 3.9620, 5.0942]], requires_grad=True)\n",
      "i =  177 , motion_estimation =  tensor([[2.9778, 3.9601, 5.0983]], requires_grad=True)\n",
      "i =  178 , motion_estimation =  tensor([[2.9787, 3.9543, 5.1024]], requires_grad=True)\n",
      "i =  179 , motion_estimation =  tensor([[2.9771, 3.9487, 5.1055]], requires_grad=True)\n",
      "i =  180 , motion_estimation =  tensor([[2.9768, 3.9433, 5.1059]], requires_grad=True)\n",
      "i =  181 , motion_estimation =  tensor([[2.9753, 3.9363, 5.1046]], requires_grad=True)\n",
      "i =  182 , motion_estimation =  tensor([[2.9761, 3.9311, 5.1025]], requires_grad=True)\n",
      "i =  183 , motion_estimation =  tensor([[2.9802, 3.9275, 5.0985]], requires_grad=True)\n",
      "i =  184 , motion_estimation =  tensor([[2.9811, 3.9241, 5.0959]], requires_grad=True)\n",
      "i =  185 , motion_estimation =  tensor([[2.9825, 3.9236, 5.0903]], requires_grad=True)\n",
      "i =  186 , motion_estimation =  tensor([[2.9819, 3.9249, 5.0859]], requires_grad=True)\n",
      "i =  187 , motion_estimation =  tensor([[2.9823, 3.9266, 5.0818]], requires_grad=True)\n",
      "i =  188 , motion_estimation =  tensor([[2.9836, 3.9280, 5.0813]], requires_grad=True)\n",
      "i =  189 , motion_estimation =  tensor([[2.9851, 3.9295, 5.0807]], requires_grad=True)\n",
      "i =  190 , motion_estimation =  tensor([[2.9882, 3.9301, 5.0807]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  191 , motion_estimation =  tensor([[2.9900, 3.9303, 5.0820]], requires_grad=True)\n",
      "i =  192 , motion_estimation =  tensor([[2.9895, 3.9327, 5.0836]], requires_grad=True)\n",
      "i =  193 , motion_estimation =  tensor([[2.9862, 3.9374, 5.0873]], requires_grad=True)\n",
      "i =  194 , motion_estimation =  tensor([[2.9804, 3.9409, 5.0871]], requires_grad=True)\n",
      "i =  195 , motion_estimation =  tensor([[2.9768, 3.9443, 5.0863]], requires_grad=True)\n",
      "i =  196 , motion_estimation =  tensor([[2.9750, 3.9462, 5.0861]], requires_grad=True)\n",
      "i =  197 , motion_estimation =  tensor([[2.9747, 3.9483, 5.0866]], requires_grad=True)\n",
      "i =  198 , motion_estimation =  tensor([[2.9725, 3.9494, 5.0888]], requires_grad=True)\n",
      "i =  199 , motion_estimation =  tensor([[2.9735, 3.9480, 5.0914]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Estimating the unknown displacement between the camera and the origin\n",
    "\n",
    "# Defining optimisation variable\n",
    "motion_estimate = torch.zeros(motion_gt.shape, \n",
    "                              device=device, \n",
    "                              requires_grad=True)\n",
    "\n",
    "\n",
    "# Defining Torch optimizer\n",
    "optimizer = torch.optim.SGD([motion_estimate], lr=0.1, momentum=0.9)\n",
    "\n",
    "\n",
    "# Running SGD for 200 iterations \n",
    "for i in range(0, 200):\n",
    "    optimizer.zero_grad()\n",
    "    current_mesh_batch = mesh_batch.offset_verts(motion_estimate.repeat(num_vertices,1))\n",
    "    \n",
    "    # we randomly sample 5,000 points from the two meshes and compute their Chamfer distances\n",
    "    sample_trg = sample_points_from_meshes(current_mesh_batch, 5000)\n",
    "    sample_src = sample_points_from_meshes(mesh_batch_noisy, 5000)\n",
    "    loss, _ = chamfer_distance(sample_trg, sample_src)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('i = ', i, ', motion_estimation = ', motion_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b7540b",
   "metadata": {},
   "source": [
    "Main Outcome: The optimization process converges to the [3,4,5] ground-truth location very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb976ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".3d",
   "language": "python",
   "name": ".3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
