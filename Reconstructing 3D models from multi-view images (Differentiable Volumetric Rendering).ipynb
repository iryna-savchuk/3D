{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7769118b",
   "metadata": {},
   "source": [
    "## Understanding  Ray Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Linraries and Packages\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from pytorch3d.renderer import (\n",
    "    FoVPerspectiveCameras,\n",
    "    PointLights,\n",
    "    look_at_view_transform,\n",
    "    NDCGridRaysampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65dd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up PyTorch device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: CPU only, this will be more slowly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c174eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a batch of 10 cameras \n",
    "num_views: int = 10\n",
    "azimuth_range: float = 180\n",
    "elev = torch.linspace(0, 0, num_views)  # keep constant\n",
    "azim = torch.linspace(-azimuth_range, azimuth_range, num_views) + 180.0\n",
    "lights = PointLights(device=device, location=[[0.0, 0.0, -3.0]])\n",
    "\n",
    "R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
    "cameras = FoVPerspectiveCameras(device=device, R=R, T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1316c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a ray sampler\n",
    "image_size = 64\n",
    "volume_extent_world = 3.0\n",
    "\n",
    "raysampler = NDCGridRaysampler(\n",
    "    image_width=image_size,\n",
    "    image_height=image_size,\n",
    "    n_pts_per_ray=50,\n",
    "    min_depth=0.1,\n",
    "    max_depth=volume_extent_world,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letting the ray sampler know where our cameras are and in what directions they are pointing\n",
    "# Getting the sampled rays and points into ray_bundle\n",
    "ray_bundle = raysampler(cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out information on ray bundle\n",
    "print('ray_bundle origins tensor shape = ', ray_bundle.origins.shape)\n",
    "print('ray_bundle directions shape = ', ray_bundle.directions.shape)\n",
    "print('ray_bundle lengths = ', ray_bundle.lengths.shape)\n",
    "print('ray_bundle xys shape = ', ray_bundle.xys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e3b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving ray bundle\n",
    "torch.save({\n",
    "    'output/ray_bundle': ray_bundle\n",
    "}, 'ray_sampling.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".3d",
   "language": "python",
   "name": ".3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
