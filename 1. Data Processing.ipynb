{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05af7bfe",
   "metadata": {},
   "source": [
    "## 3D Data Representations\n",
    "**1) 3D Point Cloud** - a collection of 3D points, where each point is represented by one 3-dimensional tuple (x, y, z).\n",
    "Issues:\n",
    "- From the DL point of view, 3D point clouds are one of the unordered and irregular data types: there is no clear and regular definition of the neighbourhood, so convolutions usually cannot be applied to point clouds. Thus, special types of DL models need to be used, like [PointNet](https://arxiv.org/abs/1612.00593). \n",
    "- Heterogeneous data issue, meaning for one training dataset, different point clouds may contain a different number of 3D points. Heterogeneous data can create some difficulties when using mini-batch Gradient Descent training.\n",
    "\n",
    "**2) Mesh Representation** - another widely used 3D data representation. Each mesh contains a set of 3D points(vertices) and a set of polygons(faces), which are defined on the vertices. In most cases, meshes are obtained from post-processing from raw measurements of depth cameras or manually created during 3D asset design. \n",
    "Meshes contain additional geometric information and encode topology, and, like 3D point clouds, have heterogeneous data issues.\n",
    "\n",
    "**3) Voxel Representation** - a representation that is based on voxels, a counterpart of pixels in 3D Computer Vision. A voxel is defined by dividing a 3D cube into small-sized cubes - each of the cubes is called a voxel. Important definitions related to voxels:\n",
    "- SDF(Signed Distance Function): signed distance between the voxel center and the closest point on the surface (a positive sign means the voxel center is outside an object),\n",
    "- TSDF(Truncated Signed Distance Function): truncated values of SDF, so they range from -1 to +1. \n",
    "Voxel representation is ordered and regular, so it is possible to use convolution filters. The potential disadvantage - voxel representation requires more computer memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07aaa10",
   "metadata": {},
   "source": [
    "## Working with Ply Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be37ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open3d package is handy for visualizing 3D data\n",
    "# !pip install open3d\n",
    "import open3d\n",
    "\n",
    "from pytorch3d.io import load_ply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690a427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4e2a0",
   "metadata": {},
   "source": [
    "### Example 1 - 'cube.ply'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "419e9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open3d package is handy for visualizing 3D data\n",
    "# !pip install open3d\n",
    "import open3d\n",
    "\n",
    "from pytorch3d.io import load_ply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00a251f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_file = data_folder+\"cube.ply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e18cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Load the mesh \n",
    "mesh = open3d.io.read_triangle_mesh(mesh_file)\n",
    "\n",
    "# Create a visualizer object and add the mesh\n",
    "vis = open3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(mesh)\n",
    "\n",
    "# Set mesh properties\n",
    "mesh_show_wireframe = True\n",
    "mesh_show_back_face = True\n",
    "\n",
    "# Render the visualization and wait for window close\n",
    "vis.get_render_option().mesh_show_wireframe = mesh_show_wireframe\n",
    "vis.get_render_option().mesh_show_back_face = mesh_show_back_face\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d116b455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of vertices =  <class 'torch.Tensor'> , type of faces =  <class 'torch.Tensor'>\n",
      "vertices =  tensor([[-1., -1., -1.],\n",
      "        [ 1., -1., -1.],\n",
      "        [ 1.,  1., -1.],\n",
      "        [-1.,  1., -1.],\n",
      "        [-1., -1.,  1.],\n",
      "        [ 1., -1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [-1.,  1.,  1.]])\n",
      "faces =  tensor([[0, 1, 2],\n",
      "        [5, 4, 7],\n",
      "        [6, 2, 1],\n",
      "        [3, 7, 4],\n",
      "        [7, 3, 2],\n",
      "        [5, 1, 0],\n",
      "        [0, 2, 3],\n",
      "        [5, 7, 6],\n",
      "        [6, 1, 5],\n",
      "        [3, 4, 0],\n",
      "        [7, 2, 6],\n",
      "        [5, 0, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Loading the same file with PyTorch3D\n",
    "vertices, faces = load_ply(mesh_file) #\n",
    "\n",
    "print('Type of vertices = ', type(vertices), \", type of faces = \", type(faces))\n",
    "print('vertices = ', vertices)\n",
    "print('faces = ', faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18284be",
   "metadata": {},
   "source": [
    "### Example 2 - 'parallel_plane_mono.ply'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5cc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_file = data_folder+\"parallel_plane_mono.ply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4159ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the mesh using open3D\n",
    "mesh = open3d.io.read_triangle_mesh(mesh_file)\n",
    "open3d.visualization.draw_geometries([mesh],\n",
    "                                     mesh_show_wireframe = True,\n",
    "                                     mesh_show_back_face = True,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaab66de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of vertices =  <class 'torch.Tensor'> , type of faces =  <class 'torch.Tensor'>\n",
      "vertices =  tensor([[-1., -1., -1.],\n",
      "        [ 1., -1., -1.],\n",
      "        [ 1.,  1., -1.],\n",
      "        [-1.,  1., -1.],\n",
      "        [-1., -1.,  1.],\n",
      "        [ 1., -1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [-1.,  1.,  1.]])\n",
      "faces =  tensor([[0, 1, 2],\n",
      "        [0, 2, 3],\n",
      "        [5, 4, 7],\n",
      "        [5, 7, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Loading the same file with PyTorch3D\n",
    "vertices, faces = load_ply(mesh_file)\n",
    "print('Type of vertices = ', type(vertices), \", type of faces = \", type(faces))\n",
    "print('vertices = ', vertices)\n",
    "print('faces = ', faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cde662",
   "metadata": {},
   "source": [
    "### Example 3 - 'parallel_plane_color.ply'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf9c96",
   "metadata": {},
   "source": [
    "In the .ply file in this example, additional properties are defined for each vertex - red, green and blue properties of 'uchar' data type (see 'parallel_plane_color.ply' for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc099a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_file = data_folder+\"parallel_plane_color.ply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2922c5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the mesh using open3D\n",
    "mesh = open3d.io.read_triangle_mesh(mesh_file)\n",
    "open3d.visualization.draw_geometries([mesh],\n",
    "                                     mesh_show_wireframe = True,\n",
    "                                     mesh_show_back_face = True,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f22ec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of vertices =  <class 'torch.Tensor'> , type of faces =  <class 'torch.Tensor'>\n",
      "vertices =  tensor([[-1., -1., -1.],\n",
      "        [ 1., -1., -1.],\n",
      "        [ 1.,  1., -1.],\n",
      "        [-1.,  1., -1.],\n",
      "        [-1., -1.,  1.],\n",
      "        [ 1., -1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [-1.,  1.,  1.]])\n",
      "faces =  tensor([[0, 1, 2],\n",
      "        [0, 2, 3],\n",
      "        [5, 4, 7],\n",
      "        [5, 7, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Loading the same file with PyTorch3D\n",
    "vertices, faces = load_ply(mesh_file)\n",
    "print('Type of vertices = ', type(vertices), \", type of faces = \", type(faces))\n",
    "print('vertices = ', vertices)\n",
    "print('faces = ', faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d440d1a",
   "metadata": {},
   "source": [
    "### Example 4 - 'cow.ply'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3562b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_file = data_folder+\"cow.ply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73cf29f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the mesh using open3D\n",
    "mesh = open3d.io.read_triangle_mesh(mesh_file)\n",
    "open3d.visualization.draw_geometries([mesh],\n",
    "                                     mesh_show_wireframe = True,\n",
    "                                     mesh_show_back_face = True,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a1986",
   "metadata": {},
   "source": [
    "## Working with OBJ Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b45dd",
   "metadata": {},
   "source": [
    "### Example 1 - 'cube.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8032a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.io import load_obj\n",
    "\n",
    "obj_file = data_folder+\"cube.obj\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837100ea",
   "metadata": {},
   "source": [
    "We will have a look at 'cube.obj' file. The first line in it, declares the companion MaterialTemplateLibrary(MTL) file - cube.mtl. \n",
    "\n",
    "The MTL file describes surface shading properties: \n",
    "\n",
    "- Ka: Specifies an ambient color\n",
    "- Kd: Specifies a diffuse color\n",
    "- Ks: Specifies a specular color\n",
    "- Ns: Defines the focus of specular highlights\n",
    "- Ni: Defines the optical density (a.k.a index of refraction)\n",
    "- d: Specifies a factor for dissolve\n",
    "- illum: Specifies an illumination model\n",
    "- map_Kd: Specifies a color texture file to be applied to the diffuse reflectivity of the material\n",
    "\n",
    "The 'cube.obj' file can be opened by both libraries - Open3D and PyTorch3D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8edb374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the mesh using open3D\n",
    "mesh = open3d.io.read_triangle_mesh(obj_file)\n",
    "open3d.visualization.draw_geometries([mesh],\n",
    "                 mesh_show_wireframe = True,\n",
    "                 mesh_show_back_face = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4e23774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of vertices =  <class 'torch.Tensor'>\n",
      "Type of faces =  <class 'pytorch3d.io.obj_io.Faces'>\n",
      "Type of aux =  <class 'pytorch3d.io.obj_io.Properties'>\n",
      "vertices =  tensor([[-0.5000, -0.5000,  0.5000],\n",
      "        [-0.5000, -0.5000, -0.5000],\n",
      "        [-0.5000,  0.5000, -0.5000],\n",
      "        [-0.5000,  0.5000,  0.5000],\n",
      "        [ 0.5000, -0.5000,  0.5000],\n",
      "        [ 0.5000, -0.5000, -0.5000],\n",
      "        [ 0.5000,  0.5000, -0.5000],\n",
      "        [ 0.5000,  0.5000,  0.5000]])\n",
      "faces =  Faces(verts_idx=tensor([[0, 1, 2],\n",
      "        [5, 4, 7],\n",
      "        [6, 2, 1],\n",
      "        [3, 7, 4],\n",
      "        [7, 3, 2],\n",
      "        [5, 1, 0],\n",
      "        [0, 2, 3],\n",
      "        [5, 7, 6],\n",
      "        [6, 1, 5],\n",
      "        [3, 4, 0],\n",
      "        [7, 2, 6],\n",
      "        [5, 0, 4]]), normals_idx=tensor([[-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1]]), textures_idx=tensor([[-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1],\n",
      "        [-1, -1, -1]]), materials_idx=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "aux =  Properties(normals=None, verts_uvs=None, material_colors={'Door': {'ambient_color': tensor([0.8000, 0.6000, 0.4000]), 'diffuse_color': tensor([0.8000, 0.6000, 0.4000]), 'specular_color': tensor([0.9000, 0.9000, 0.9000]), 'shininess': tensor([0.])}}, texture_images={}, texture_atlas=None)\n"
     ]
    }
   ],
   "source": [
    "# Loading the same file with PyTorch3D\n",
    "vertices, faces, aux = load_obj(obj_file)\n",
    "\n",
    "print('Type of vertices = ', type(vertices))\n",
    "print(\"Type of faces = \", type(faces))\n",
    "print(\"Type of aux = \", type(aux))\n",
    "print('vertices = ', vertices)\n",
    "print('faces = ', faces)\n",
    "print('aux = ', aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863b81a",
   "metadata": {},
   "source": [
    "The returned **vertices** variable is a PyTorch tensor with a shape of 8x3. Each row is a vertex with the x, y, and z coordinates. \n",
    "The returned **faces** variable is a named tuple of three PyTorch tensors: verts_idx, normals_idx, and textures_idx. In the example, all the normals_idx and textures_idx tensors are invalid because the file \"cube.obj\" does not include definitions for normal and textures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a801985",
   "metadata": {},
   "source": [
    "### Example 2 - 'cube_texture.obj'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1fc63e",
   "metadata": {},
   "source": [
    "The 'cube_texture.obj' file is similar to the file 'cube.obj' file, except for:\n",
    "- Additional lines starting with vt: each such line declares a texture vertex with x and y coordinates. Each texture vertex defines a color. The color is the pixel color at a so-called texture image, where the pixel location is the x coordinate of the texture vertex x width, and the y coordinate of the texture vertex x height. The texture image would be defined in the cube_texture.mtl companion.\n",
    "- There are additional lines starting with vn. Each such line declares a normal vector.\n",
    "- Each face definition line now contains more information about each vertex.\n",
    "\n",
    "The companion file is \"cube_texture.mtl\".\n",
    "Again, it is possible to use  both Open3D and PyTorch3D to load the mesh in the \"cube_texture.obj\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fc5aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d\n",
    "from pytorch3d.io import load_obj\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38752289",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_file = data_folder+\"cube_texture.obj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b09a057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the mesh using open3D\n",
    "mesh = open3d.io.read_triangle_mesh(mesh_file)\n",
    "open3d.visualization.draw_geometries([mesh],\n",
    "                  mesh_show_wireframe = True,\n",
    "                  mesh_show_back_face = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5af693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of vertices =  <class 'torch.Tensor'>\n",
      "Type of faces =  <class 'pytorch3d.io.obj_io.Faces'>\n",
      "Type of aux =  <class 'pytorch3d.io.obj_io.Properties'>\n",
      "vertices =  tensor([[ 1.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000, -1.0000,  1.0000],\n",
      "        [-1.0000, -1.0000,  1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000, -1.0000]])\n",
      "faces =  Faces(verts_idx=tensor([[1, 2, 3],\n",
      "        [7, 6, 5],\n",
      "        [4, 5, 1],\n",
      "        [5, 6, 2],\n",
      "        [2, 6, 7],\n",
      "        [0, 3, 7],\n",
      "        [0, 1, 3],\n",
      "        [4, 7, 5],\n",
      "        [0, 4, 1],\n",
      "        [1, 5, 2],\n",
      "        [3, 2, 7],\n",
      "        [4, 0, 7]]), normals_idx=tensor([[0, 0, 0],\n",
      "        [1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4],\n",
      "        [5, 5, 5],\n",
      "        [0, 0, 0],\n",
      "        [1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4],\n",
      "        [5, 5, 5]]), textures_idx=tensor([[ 0,  1,  2],\n",
      "        [ 0,  3,  4],\n",
      "        [ 5,  6,  7],\n",
      "        [ 7,  4,  3],\n",
      "        [ 8,  9, 10],\n",
      "        [11, 12, 10],\n",
      "        [ 3,  0,  2],\n",
      "        [13,  0,  4],\n",
      "        [11,  5,  7],\n",
      "        [11,  7,  3],\n",
      "        [12,  8, 10],\n",
      "        [ 5, 11, 10]]), materials_idx=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "aux =  Properties(normals=tensor([[ 0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.],\n",
      "        [ 1.,  0.,  0.],\n",
      "        [-0.,  0.,  1.],\n",
      "        [-1., -0., -0.],\n",
      "        [ 0.,  0., -1.]]), verts_uvs=tensor([[1.0000, 0.3333],\n",
      "        [1.0000, 0.6667],\n",
      "        [0.6667, 0.6667],\n",
      "        [0.6667, 0.3333],\n",
      "        [0.6667, 0.0000],\n",
      "        [0.0000, 0.3333],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3333, 0.0000],\n",
      "        [0.3333, 1.0000],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0000, 0.6667],\n",
      "        [0.3333, 0.3333],\n",
      "        [0.3333, 0.6667],\n",
      "        [1.0000, 0.0000]]), material_colors={'Skin': {'ambient_color': tensor([0.2000, 0.2000, 0.2000]), 'diffuse_color': tensor([0.8275, 0.7922, 0.7725]), 'specular_color': tensor([0., 0., 0.]), 'shininess': tensor([0.])}}, texture_images={'Skin': tensor([[[0.2078, 0.1765, 0.1020],\n",
      "         [0.2039, 0.1725, 0.0980],\n",
      "         [0.1961, 0.1647, 0.0902],\n",
      "         ...,\n",
      "         [0.2588, 0.2275, 0.1451],\n",
      "         [0.2510, 0.2196, 0.1373],\n",
      "         [0.2353, 0.2039, 0.1216]],\n",
      "\n",
      "        [[0.1922, 0.1608, 0.0863],\n",
      "         [0.1882, 0.1569, 0.0824],\n",
      "         [0.1922, 0.1608, 0.0863],\n",
      "         ...,\n",
      "         [0.2706, 0.2392, 0.1569],\n",
      "         [0.2510, 0.2196, 0.1373],\n",
      "         [0.2353, 0.2039, 0.1216]],\n",
      "\n",
      "        [[0.1843, 0.1529, 0.0784],\n",
      "         [0.1843, 0.1529, 0.0784],\n",
      "         [0.1882, 0.1569, 0.0824],\n",
      "         ...,\n",
      "         [0.2784, 0.2471, 0.1647],\n",
      "         [0.2510, 0.2196, 0.1373],\n",
      "         [0.2353, 0.2039, 0.1216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3216, 0.2706, 0.2039],\n",
      "         [0.3137, 0.2627, 0.1961],\n",
      "         [0.3020, 0.2588, 0.1882],\n",
      "         ...,\n",
      "         [0.1843, 0.1490, 0.0824],\n",
      "         [0.2039, 0.1686, 0.1020],\n",
      "         [0.2196, 0.1843, 0.1176]],\n",
      "\n",
      "        [[0.2941, 0.2510, 0.1804],\n",
      "         [0.2471, 0.2039, 0.1333],\n",
      "         [0.2314, 0.1882, 0.1176],\n",
      "         ...,\n",
      "         [0.2431, 0.2078, 0.1490],\n",
      "         [0.2235, 0.1882, 0.1294],\n",
      "         [0.2235, 0.1882, 0.1294]],\n",
      "\n",
      "        [[0.2784, 0.2353, 0.1647],\n",
      "         [0.2353, 0.1922, 0.1216],\n",
      "         [0.2157, 0.1725, 0.1020],\n",
      "         ...,\n",
      "         [0.2431, 0.2078, 0.1490],\n",
      "         [0.2235, 0.1882, 0.1294],\n",
      "         [0.2235, 0.1882, 0.1294]]])}, texture_atlas=None)\n"
     ]
    }
   ],
   "source": [
    "# Loading the same file with PyTorch3D\n",
    "vertices, faces, aux = load_obj(mesh_file)\n",
    "\n",
    "print('Type of vertices = ', type(vertices))\n",
    "print(\"Type of faces = \", type(faces))\n",
    "print(\"Type of aux = \", type(aux))\n",
    "\n",
    "print('vertices = ', vertices)\n",
    "print('faces = ', faces)\n",
    "print('aux = ', aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f909e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texture_images type =  <class 'dict'>\n",
      "Skin\n",
      "torch.Size([250, 250, 3])\n"
     ]
    }
   ],
   "source": [
    "texture_images = getattr(aux, 'texture_images')\n",
    "print('texture_images type = ', type(texture_images))\n",
    "for key in texture_images:\n",
    "    print(key)\n",
    "\n",
    "print(texture_images['Skin'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e225af",
   "metadata": {},
   "source": [
    "The fields 'normals_idx' and 'textures_idx' of 'faces' contain valid indices now (instead of taking a -1 value). The field 'normals' of 'aux' is a PyTorch tensor now (instead of being None). The field 'verts_uvs' of 'aux' is a PyTorch tensor now (instead of being None).\n",
    "\n",
    "The field 'texture_images' of the 'aux' variable is not an empty dictionary any longer. The texture_images dictionary contains one entry with a key, Skin, and a PyTorch tensor with a shape of (250, 250, 3). This tensor is exactly the same as the image contained in the wal67ar_small.jpg file, as defined in the mtl_texture.mtl file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a08e15",
   "metadata": {},
   "source": [
    "## Coding for camera models and coordination systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a1fcafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import open3d\n",
    "import torch\n",
    "import pytorch3d\n",
    "from pytorch3d.io import load_obj\n",
    "from scipy.spatial.transform import Rotation as Rotation\n",
    "\n",
    "from pytorch3d.renderer.cameras import PerspectiveCameras, OrthographicCameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4a13ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Load and visualize the mesh with Open3D\n",
    "mesh_file = data_folder+\"cube.obj\"\n",
    "\n",
    "mesh = open3d.io.read_triangle_mesh(mesh_file)\n",
    "open3d.visualization.draw_geometries([mesh],\n",
    "                 mesh_show_wireframe = True,\n",
    "                 mesh_show_back_face = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "448b3a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mini-batch of 8 cameras\n",
    "image_size = torch.ones(8, 2)\n",
    "\n",
    "image_size[:,0] = image_size[:,0] * 1024\n",
    "image_size[:,1] = image_size[:,1] * 512\n",
    "image_size = image_size.to('cpu') # image_size.cuda()\n",
    "\n",
    "focal_length = torch.ones(8, 2)\n",
    "focal_length[:,0] = focal_length[:,0] * 1200\n",
    "focal_length[:,1] = focal_length[:,1] * 300\n",
    "focal_length = focal_length.to('cpu') #focal_length.cuda()\n",
    "\n",
    "principal_point = torch.ones(8, 2)\n",
    "principal_point[:,0] = principal_point[:,0] * 512\n",
    "principal_point[:,1] = principal_point[:,1] * 256\n",
    "principal_point =  principal_point.to('cpu') # principal_point.cuda()\n",
    "\n",
    "R = Rotation.from_euler('zyx', [\n",
    "[n*5, n, n]  for n in range(-4, 4, 1)], degrees=True).as_matrix()\n",
    "R = torch.from_numpy(R).to('cpu') #torch.from_numpy(R).cuda()\n",
    "\n",
    "T = [ [n, 0, 0] for n in range(-4, 4, 1)]\n",
    "T =  torch.FloatTensor(T).to('cpu') # torch.FloatTensor(T).cuda()\n",
    "\n",
    "#print('R = ', R)\n",
    "#exit()\n",
    "\n",
    "camera = PerspectiveCameras(focal_length = focal_length,\n",
    "                            principal_point = principal_point,\n",
    "                            in_ndc = False,\n",
    "                            image_size = image_size,\n",
    "                            R = R,\n",
    "                            T = T,\n",
    "                            device = 'cpu') #device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e089c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of world_to_screen_transform =  <class 'pytorch3d.transforms.transform3d.Transform3d'>\n"
     ]
    }
   ],
   "source": [
    "world_to_view_transform = camera.get_world_to_view_transform()\n",
    "world_to_screen_transform = camera.get_full_projection_transform()\n",
    "print('The type of world_to_screen_transform = ', type(world_to_screen_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47a81288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world_to_view_vertices =  tensor([[[-4.2558, -0.6610,  0.4977],\n",
      "         [-4.3450, -0.6193, -0.4975],\n",
      "         [-4.6816,  0.3198, -0.4279],\n",
      "         [-4.5924,  0.2781,  0.5672],\n",
      "         [-3.3184, -0.3198,  0.4279],\n",
      "         [-3.4076, -0.2781, -0.5672],\n",
      "         [-3.7442,  0.6610, -0.4977],\n",
      "         [-3.6550,  0.6193,  0.4975]],\n",
      "\n",
      "        [[-3.3224, -0.6304,  0.4987],\n",
      "         [-3.3864, -0.5934, -0.4986],\n",
      "         [-3.6422,  0.3719, -0.4463],\n",
      "         [-3.5782,  0.3349,  0.5509],\n",
      "         [-2.3578, -0.3719,  0.4463],\n",
      "         [-2.4218, -0.3349, -0.5509],\n",
      "         [-2.6776,  0.6304, -0.4987],\n",
      "         [-2.6136,  0.5934,  0.4986]],\n",
      "\n",
      "        [[-2.3857, -0.5931,  0.4994],\n",
      "         [-2.4261, -0.5648, -0.4994],\n",
      "         [-2.5985,  0.4196, -0.4645],\n",
      "         [-2.5581,  0.3913,  0.5343],\n",
      "         [-1.4015, -0.4196,  0.4645],\n",
      "         [-1.4419, -0.3913, -0.5343],\n",
      "         [-1.6143,  0.5931, -0.4994],\n",
      "         [-1.5739,  0.5648,  0.4994]],\n",
      "\n",
      "        [[-1.4451, -0.5495,  0.4998],\n",
      "         [-1.4641, -0.5337, -0.4998],\n",
      "         [-1.5509,  0.4624, -0.4824],\n",
      "         [-1.5320,  0.4465,  0.5173],\n",
      "         [-0.4491, -0.4624,  0.4824],\n",
      "         [-0.4680, -0.4465, -0.5173],\n",
      "         [-0.5549,  0.5495, -0.4998],\n",
      "         [-0.5359,  0.5337,  0.4998]],\n",
      "\n",
      "        [[-0.5000, -0.5000,  0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000,  0.5000, -0.5000],\n",
      "         [-0.5000,  0.5000,  0.5000],\n",
      "         [ 0.5000, -0.5000,  0.5000],\n",
      "         [ 0.5000, -0.5000, -0.5000],\n",
      "         [ 0.5000,  0.5000, -0.5000],\n",
      "         [ 0.5000,  0.5000,  0.5000]],\n",
      "\n",
      "        [[ 0.4503, -0.4450,  0.4998],\n",
      "         [ 0.4662, -0.4639, -0.4998],\n",
      "         [ 0.5536,  0.5321, -0.5173],\n",
      "         [ 0.5378,  0.5510,  0.4824],\n",
      "         [ 1.4464, -0.5321,  0.5173],\n",
      "         [ 1.4622, -0.5510, -0.4824],\n",
      "         [ 1.5497,  0.4450, -0.4998],\n",
      "         [ 1.5338,  0.4639,  0.4998]],\n",
      "\n",
      "        [[ 1.4064, -0.3850,  0.4994],\n",
      "         [ 1.4347, -0.4254, -0.4994],\n",
      "         [ 1.6094,  0.5586, -0.5343],\n",
      "         [ 1.5811,  0.5990,  0.4645],\n",
      "         [ 2.3906, -0.5586,  0.5343],\n",
      "         [ 2.4189, -0.5990, -0.4645],\n",
      "         [ 2.5936,  0.3850, -0.4994],\n",
      "         [ 2.5653,  0.4254,  0.4994]],\n",
      "\n",
      "        [[ 2.3687, -0.3207,  0.4986],\n",
      "         [ 2.4056, -0.3848, -0.4987],\n",
      "         [ 2.6667,  0.5791, -0.5509],\n",
      "         [ 2.6298,  0.6432,  0.4463],\n",
      "         [ 3.3333, -0.5791,  0.5509],\n",
      "         [ 3.3702, -0.6432, -0.4463],\n",
      "         [ 3.6313,  0.3207, -0.4986],\n",
      "         [ 3.5944,  0.3848,  0.4987]]])\n",
      "world_to_screen_vertices =  tensor([[[-9.7500e+03, -1.4247e+02,  2.0094e+00],\n",
      "         [ 1.0993e+04,  6.2943e+02, -2.0101e+00],\n",
      "         [ 1.3641e+04,  3.1776e+01, -2.3370e+00],\n",
      "         [-9.2032e+03,  4.0306e+02,  1.7629e+00],\n",
      "         [-8.7941e+03,  3.1776e+01,  2.3370e+00],\n",
      "         [ 7.7209e+03,  4.0306e+02, -1.7629e+00],\n",
      "         [ 9.5405e+03, -1.4247e+02, -2.0094e+00],\n",
      "         [-8.3044e+03,  6.2943e+02,  2.0101e+00]],\n",
      "\n",
      "        [[-7.4830e+03, -1.2325e+02,  2.0053e+00],\n",
      "         [ 8.6623e+03,  6.1303e+02, -2.0056e+00],\n",
      "         [ 1.0304e+04,  6.0039e+00, -2.2405e+00],\n",
      "         [-7.2818e+03,  4.3837e+02,  1.8151e+00],\n",
      "         [-5.8271e+03,  6.0039e+00,  2.2405e+00],\n",
      "         [ 5.7870e+03,  4.3837e+02, -1.8151e+00],\n",
      "         [ 6.9555e+03, -1.2325e+02, -2.0053e+00],\n",
      "         [-5.7783e+03,  6.1303e+02,  2.0056e+00]],\n",
      "\n",
      "        [[-5.2206e+03, -1.0031e+02,  2.0024e+00],\n",
      "         [ 6.3420e+03,  5.9532e+02, -2.0025e+00],\n",
      "         [ 7.2249e+03, -1.4996e+01, -2.1528e+00],\n",
      "         [-5.2335e+03,  4.7571e+02,  1.8717e+00],\n",
      "         [-3.1087e+03, -1.4996e+01,  2.1528e+00],\n",
      "         [ 3.7506e+03,  4.7571e+02, -1.8717e+00],\n",
      "         [ 4.3909e+03, -1.0031e+02, -2.0024e+00],\n",
      "         [-3.2700e+03,  5.9532e+02,  2.0025e+00]],\n",
      "\n",
      "        [[-2.9574e+03, -7.3823e+01,  2.0006e+00],\n",
      "         [ 4.0268e+03,  5.7630e+02, -2.0006e+00],\n",
      "         [ 4.3700e+03, -3.1562e+01, -2.0730e+00],\n",
      "         [-3.0418e+03,  5.1496e+02,  1.9331e+00],\n",
      "         [-6.0519e+02, -3.1562e+01,  2.0730e+00],\n",
      "         [ 1.5977e+03,  5.1496e+02, -1.9331e+00],\n",
      "         [ 1.8440e+03, -7.3823e+01, -2.0006e+00],\n",
      "         [-7.7467e+02,  5.7630e+02,  2.0006e+00]],\n",
      "\n",
      "        [[-6.8800e+02, -4.4000e+01,  2.0000e+00],\n",
      "         [ 1.7120e+03,  5.5600e+02, -2.0000e+00],\n",
      "         [ 1.7120e+03, -4.4000e+01, -2.0000e+00],\n",
      "         [-6.8800e+02,  5.5600e+02,  2.0000e+00],\n",
      "         [ 1.7120e+03, -4.4000e+01,  2.0000e+00],\n",
      "         [-6.8800e+02,  5.5600e+02, -2.0000e+00],\n",
      "         [-6.8800e+02, -4.4000e+01, -2.0000e+00],\n",
      "         [ 1.7120e+03,  5.5600e+02,  2.0000e+00]],\n",
      "\n",
      "        [[ 1.5931e+03, -1.1072e+01,  2.0006e+00],\n",
      "         [-6.0719e+02,  5.3442e+02, -2.0006e+00],\n",
      "         [-7.7229e+02, -5.2599e+01, -1.9331e+00],\n",
      "         [ 1.8497e+03,  5.9868e+02,  2.0730e+00],\n",
      "         [ 3.8672e+03, -5.2599e+01,  1.9331e+00],\n",
      "         [-3.1254e+03,  5.9868e+02, -2.0730e+00],\n",
      "         [-3.2084e+03, -1.1072e+01, -2.0006e+00],\n",
      "         [ 4.1943e+03,  5.3442e+02,  2.0006e+00]],\n",
      "\n",
      "        [[ 3.8915e+03,  2.4705e+01,  2.0025e+00],\n",
      "         [-2.9353e+03,  5.1157e+02, -2.0024e+00],\n",
      "         [-3.1028e+03, -5.7631e+01, -1.8717e+00],\n",
      "         [ 4.5967e+03,  6.4285e+02,  2.1528e+00],\n",
      "         [ 5.8813e+03, -5.7631e+01,  1.8717e+00],\n",
      "         [-5.7370e+03,  6.4285e+02, -2.1528e+00],\n",
      "         [-5.7204e+03,  2.4705e+01, -2.0025e+00],\n",
      "         [ 6.6762e+03,  5.1157e+02,  2.0024e+00]],\n",
      "\n",
      "        [[ 6.2128e+03,  6.3053e+01,  2.0056e+00],\n",
      "         [-5.2769e+03,  4.8747e+02, -2.0053e+00],\n",
      "         [-5.2965e+03, -5.9360e+01, -1.8151e+00],\n",
      "         [ 7.5824e+03,  6.8834e+02,  2.2405e+00],\n",
      "         [ 7.7723e+03, -5.9360e+01,  1.8151e+00],\n",
      "         [-8.5491e+03,  6.8834e+02, -2.2405e+00],\n",
      "         [-8.2277e+03,  6.3053e+01, -2.0056e+00],\n",
      "         [ 9.1616e+03,  4.8747e+02,  2.0053e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# Load meshes using PyTorch3D\n",
    "vertices, faces, aux = load_obj(mesh_file)\n",
    "vertices = vertices.to('cpu') #vertices.cuda()\n",
    "\n",
    "world_to_view_vertices = world_to_view_transform.transform_points(vertices)\n",
    "world_to_screen_vertices = world_to_screen_transform.transform_points(vertices)\n",
    "\n",
    "print('world_to_view_vertices = ', world_to_view_vertices)\n",
    "print('world_to_screen_vertices = ', world_to_screen_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da0d1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".3d",
   "language": "python",
   "name": ".3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
